# ğŸ“§ Email Productivity Agent

A prompt-driven intelligent email productivity system that automatically categorizes emails, extracts action items, generates draft replies, and provides a conversational chat interface for inbox management.

## ğŸ¯ Key Features

- **ğŸ“¥ Smart Inbox Management**: Load and process emails with automatic categorization
- **ğŸ·ï¸ AI-Powered Categorization**: Intelligently sorts emails into Important, Newsletter, Spam, To-Do, and Meeting
- **âœ… Action Item Extraction**: Automatically identifies tasks, deadlines, and priorities
- **âœ‰ï¸ Draft Generation**: Creates professional email replies (never sends automatically)
- **ğŸ§  Prompt Brain**: Fully customizable prompt templates that control agent behavior
- **ğŸ’¬ Email Agent Chat**: Natural language interface for querying and managing your inbox
- **ğŸ”’ Safety First**: All drafts are saved locally and never sent automatically
- **ğŸ“Š Real-time Analytics**: Track email categories and action items

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- Google Gemini API key (FREE - get it from [Google AI Studio](https://makersuite.google.com/app/apikey))

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/asneem1234/Prompt-Driven-Email-Productivity-Agent.git
   cd Prompt-Driven-Email-Productivity-Agent
   ```

2. **Install dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables** (Optional - can also enter in UI)
   ```bash
   cp .env.example .env
   # Edit .env and add your OPENAI_API_KEY
   ```

4. **Run the application**
   ```bash
   streamlit run app.py
   ```

5. **Open your browser**
   - The app will automatically open at `http://localhost:8501`
   - If not, navigate to that URL manually

## ğŸ“– Usage Guide

### 1. Initial Setup

1. Get your FREE Gemini API key from [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Enter your Gemini API key in the sidebar
3. Click "Initialize Application"
4. Wait for the success message

### 2. Load Mock Inbox

1. Click "ğŸ“‚ Load Inbox" in the sidebar
2. The system will load 15 sample emails
3. Click "âš¡ Process All" to analyze all emails

### 3. Browse Your Inbox

- View categorized emails in the main inbox view
- Filter by category (Important, Newsletter, Spam, To-Do, Meeting)
- Click "ğŸ‘ï¸ View" on any email to see details
- Expand emails to see summaries and action items

### 4. Configure Prompts (Prompt Brain)

1. Navigate to "ğŸ§  Prompt Brain"
2. Select a prompt type to edit:
   - **Categorization**: Controls how emails are sorted
   - **Action Extraction**: Defines how tasks are identified
   - **Auto-Reply**: Shapes draft reply generation
   - **Summarization**: Controls email summaries
3. Edit the prompt template (use `{sender}`, `{subject}`, `{body}` placeholders)
4. Test your prompt on sample emails
5. Save changes

### 5. Generate Draft Replies

1. Select an email in the inbox
2. Click "âœï¸ Draft Reply"
3. Review the generated draft in the "âœ‰ï¸ Drafts" page
4. Export or delete drafts as needed

### 6. Chat with Your Inbox

1. Go to "ğŸ’¬ Email Agent Chat"
2. Ask questions like:
   - "What tasks do I need to do?"
   - "Show me all urgent emails"
   - "Summarize the email from Alice"
   - "Which emails need my response?"
3. Use quick action buttons for common queries

## ğŸ—‚ï¸ Project Structure

```
Prompt-Driven-Email-Productivity-Agent/
â”œâ”€â”€ app.py                          # Main Streamlit application
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ .env.example                    # Environment variables template
â”œâ”€â”€ .gitignore                      # Git ignore file
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ mock_inbox.json            # Sample emails (15 emails)
â”‚   â”œâ”€â”€ default_prompts.json       # Default prompt templates
â”‚   â””â”€â”€ drafts.json                # Saved drafts (generated)
â””â”€â”€ src/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ llm_client.py              # LLM integration with call logging
    â”œâ”€â”€ prompt_manager.py          # Prompt template management
    â”œâ”€â”€ email_processor.py         # Email processing pipeline
    â”œâ”€â”€ draft_manager.py           # Draft generation and storage
    â””â”€â”€ email_agent.py             # Conversational agent
```

## ğŸ§  Prompt Templates

The system uses four main prompt types:

### 1. Categorization Prompt
Categorizes emails into: Important, Newsletter, Spam, To-Do, Meeting

### 2. Action Extraction Prompt
Extracts tasks with deadlines and priorities in JSON format

### 3. Auto-Reply Prompt
Generates professional draft replies based on email context

### 4. Summarization Prompt
Creates concise summaries with key points and urgency levels

**All prompts are fully customizable through the Prompt Brain interface!**

## ğŸ”§ Configuration

### Using Different LLM Models

The system uses Google Gemini by default (FREE). To use a different Gemini model, edit `src/llm_client.py`, line 19:

```python
def __init__(self, model: str = "gemini-1.5-pro"):  # Change model here
    # Options: gemini-1.5-flash (fast), gemini-1.5-pro (smarter)
```

### Customizing Email Categories

Edit the categorization prompt in the Prompt Brain to add/modify categories.

## ğŸ“‹ Mock Inbox Details

The `data/mock_inbox.json` contains 15 diverse sample emails:

- Meeting requests (with scheduling needs)
- Task assignments (with deadlines)
- Newsletters (marketing content)
- Spam/scam emails
- Status updates
- Follow-up requests
- Security alerts
- Contract reviews
- Payment reminders

## ğŸ¥ Demo Video

**Demo Video Link**: [Add your video link here after recording]

### Demo Video Timestamps:
- 0:00 - Introduction and project overview
- 0:30 - Loading mock inbox
- 1:30 - Email categorization and processing
- 2:30 - Prompt Brain: Editing and testing prompts
- 3:30 - Draft generation
- 4:30 - Email Agent chat interface
- 5:30 - Advanced features and wrap-up

## ğŸ›¡ï¸ Safety Features

- **No Automatic Sending**: All generated emails are saved as drafts only
- **API Key Security**: Keys are never stored in code or committed to git
- **Error Handling**: Graceful degradation when LLM calls fail
- **Data Privacy**: All processing happens locally; emails never leave your system except for LLM API calls

## ğŸ§ª Testing

Run basic tests:

```bash
python -c "from src.llm_client import LLMClient; print('âœ… Imports successful')"
```

## ğŸš¢ Deployment

### Using Docker (Optional)

```bash
# Build the image
docker build -t email-agent .

# Run the container
docker run -p 8501:8501 -e OPENAI_API_KEY=your_key email-agent
```

### Deploy to Cloud

The app can be deployed to:
- **Streamlit Cloud**: Push to GitHub and connect
- **Heroku**: Use the included Dockerfile
- **AWS/Azure/GCP**: Deploy as a container or Python app

## ğŸ¤ Contributing

This is a hiring challenge submission. For evaluation purposes only.

## ğŸ“„ License

This project is submitted as part of a hiring challenge.

## ğŸ‘¤ Author

**GitHub**: [@asneem1234](https://github.com/asneem1234)

## ğŸ“ Support

For questions or issues, please open an issue on GitHub.

---

**Built with â¤ï¸ using Streamlit, Google Gemini AI (FREE), and Python**
